# -*- coding: utf-8 -*-
"""cnn_karachi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TUEPEV4aFRkLh5gVa0bgnh-H4WY1aK5g
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
print(tf.__version__)

import os
from PIL import Image
import cv2
import pandas as pd

directory_in_str = 'path/to/your/data'
PATH = 'path/to/your/data'


directory = os.fsencode(directory_in_str)
i = 0
k = 0
j = 0
h = 0
image_files = [0] * 5000
mask_files = [0] * 5000
minimask_files = [0] * 5000
sam_files = [0] * 5000

count = 0
for file in os.listdir(directory):
  filename = os.fsdecode(file)
  if "slum" in filename:
    image_files[k] = PATH+filename
    k+=1



for file in os.listdir(directory):
  filename = os.fsdecode(file)
  if "mask" in filename and "minimask" not in filename:
    mask_files[i] = PATH+filename
    i+=1


for file in os.listdir(directory):
  filename = os.fsdecode(file)
  if "minimask" in filename:
    minimask_files[j] = PATH+filename
    j+=1



for file in os.listdir(directory):
  filename = os.fsdecode(file)
  if "sam" in filename:
    sam_files[h] = PATH+filename
    h+=1





image_files.sort()
mask_files.sort()
minimask_files.sort()
sam_files.sort()
print (minimask_files)

# Creating a DataFrame
data = {'IMAGES': image_files, 'MASKS': mask_files, "MINIMASK": minimask_files, 'SAMMASK': sam_files}

import numpy as np
import cv2
from PIL import Image
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation, Dropout
from tensorflow.keras.optimizers import Adam

# Create a list of image and mask pairs
data = list(zip(image_files, mask_files, minimask_files, sam_files))

def load_and_preprocess_image(image_path, mask_path, minimask_path, sam_path):
    if not isinstance(image_path, str):
        raise ValueError(f"Expected image_path to be a string, got {type(image_path)}")
    if not isinstance(mask_path, str):
        raise ValueError(f"Expected mask_path to be a string, got {type(mask_path)}")
    if not isinstance(minimask_path, str):
        raise ValueError(f"Expected minimask_path to be a string, got {type(minimask_path)}")
    if not isinstance(sam_path, str):
        raise ValueError(f"Expected sam_path to be a string, got {type(sam_path)}")

    image = cv2.imread(image_path)
    if image is None:
        raise ValueError(f"Failed to load image at {image_path}")
    image = cv2.resize(image, (256, 256))
    image = image.astype(np.float32) / 255.0

    image_rgb = Image.open(mask_path).convert('RGB')
    image_rgb = np.asarray(image_rgb)
    new_image = np.zeros((image_rgb.shape[0], image_rgb.shape[1], 3)).astype('int')

    color_match = (image_rgb[:, :, 0] == 0) & (image_rgb[:, :, 1] == 0) & (image_rgb[:, :, 2] == 0)
    new_image[color_match] = np.array([0, 0, 0]).reshape(1, 3)
    color_match = (image_rgb[:, :, 0] == 255) & (image_rgb[:, :, 1] == 255) & (image_rgb[:, :, 2] == 255)
    new_image[color_match] = np.array([1, 1, 1]).reshape(1, 3)

    new_image = new_image[:, :, 0]
    mask = new_image.astype(np.uint8)
    mask = cv2.resize(mask, (256, 256))

    # Ensure masks only contain 0 and 1
    mask[mask != 0] = 1


    image_rgb = Image.open(minimask_path).convert('RGB')
    image_np = np.array(image_rgb)
    if image_np.dtype == bool:
        binary_mask = image_np.astype(np.uint8)
    else:
        threshold = 127
        binary_mask = np.where(image_np > threshold, 1, 0)

    minimask = cv2.resize(binary_mask.astype(np.uint8), (256, 256))
    minimask = np.expand_dims(minimask, axis=-1)
    minimask = minimask.squeeze(axis=-1)

    sam_image = cv2.imread(sam_path)
    if sam_image is None:
        raise ValueError(f"Failed to load SAM image at {sam_path}")
    sam_image = cv2.resize(sam_image, (256, 256))
    sam_image = sam_image.astype(np.float32) / 255.0

    combined_input = np.concatenate((image, minimask, sam_image), axis=-1)
    return combined_input, mask

images = []
masks = []

for image_path, mask_path, minimask_path, sam_path in data:
    image, mask_final = load_and_preprocess_image(image_path, mask_path, minimask_path, sam_path)
    images.append(image)
    masks.append(mask_final)

images = np.array(images)
masks = np.array(masks)

from sklearn.model_selection import train_test_split

# Split your data into training and validation sets
images_train, images_val, masks_train, masks_val = train_test_split(images, masks, test_size=0.2, random_state=42)

print (images_val.shape)
print (masks_val.shape)
print (images_train.shape)
print (masks_train.shape)

pip install keras_tuner

import keras_tuner as kt
from tensorflow.keras.layers import Add, MaxPooling2D, SpatialDropout2D, UpSampling2D, Conv2D, BatchNormalization, Activation, Input, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

def residual_block(x, filters, kernel_size=(3, 3), padding='same', strides=1):
    res = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)
    res = BatchNormalization()(res)
    res = Activation('relu')(res)
    res = Conv2D(filters, kernel_size, padding=padding, strides=strides)(res)
    res = BatchNormalization()(res)

    shortcut = Conv2D(filters, kernel_size=(1, 1), padding='same', strides=strides)(x)
    shortcut = BatchNormalization()(shortcut)

    res = Add()([res, shortcut])
    res = Activation('relu')(res)
    return res

def build_model(hp):
    inputs = Input(shape=(256, 256, 9))

    # Encoder
    conv1 = residual_block(inputs, hp.Int('conv1_filters', min_value=32, max_value=64, step=32))
    pool1 = MaxPooling2D((2, 2))(conv1)
    pool1 = SpatialDropout2D(hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1))(pool1)

    conv2 = residual_block(pool1, hp.Int('conv2_filters', min_value=64, max_value=128, step=64))
    pool2 = MaxPooling2D((2, 2))(conv2)
    pool2 = SpatialDropout2D(hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1))(pool2)

    conv3 = residual_block(pool2, hp.Int('conv3_filters', min_value=128, max_value=256, step=128))
    pool3 = MaxPooling2D((2, 2))(conv3)
    pool3 = SpatialDropout2D(hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1))(pool3)

    conv4 = residual_block(pool3, hp.Int('conv4_filters', min_value=256, max_value=512, step=256))
    pool4 = MaxPooling2D((2, 2))(conv4)
    pool4 = SpatialDropout2D(hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1))(pool4)

    # Bottleneck
    bottleneck = residual_block(pool4, hp.Int('bottleneck_filters', min_value=512, max_value=1024, step=256))

    # Decoder
    up1 = UpSampling2D((2, 2))(bottleneck)
    up1 = Conv2D(hp.Int('up1_filters', min_value=256, max_value=512, step=128), (2, 2), padding='same')(up1)
    up1 = BatchNormalization()(up1)
    up1 = Activation('relu')(up1)
    merge1 = concatenate([conv4, up1], axis=-1)
    merge1 = SpatialDropout2D(hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1))(merge1)
    conv5 = residual_block(merge1, hp.Int('conv5_filters', min_value=256, max_value=512, step=128))

    up2 = UpSampling2D((2, 2))(conv5)
    up2 = Conv2D(hp.Int('up2_filters', min_value=128, max_value=256, step=64), (2, 2), padding='same')(up2)
    up2 = BatchNormalization()(up2)
    up2 = Activation('relu')(up2)
    merge2 = concatenate([conv3, up2], axis=-1)
    merge2 = SpatialDropout2D(hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1))(merge2)
    conv6 = residual_block(merge2, hp.Int('conv6_filters', min_value=128, max_value=256, step=64))

    up3 = UpSampling2D((2, 2))(conv6)
    up3 = Conv2D(hp.Int('up3_filters', min_value=64, max_value=128, step=32), (2, 2), padding='same')(up3)
    up3 = BatchNormalization()(up3)
    up3 = Activation('relu')(up3)
    merge3 = concatenate([conv2, up3], axis=-1)
    merge3 = SpatialDropout2D(hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1))(merge3)
    conv7 = residual_block(merge3, hp.Int('conv7_filters', min_value=64, max_value=128, step=32))

    up4 = UpSampling2D((2, 2))(conv7)
    up4 = Conv2D(hp.Int('up4_filters', min_value=32, max_value=64, step=32), (2, 2), padding='same')(up4)
    up4 = BatchNormalization()(up4)
    up4 = Activation('relu')(up4)
    merge4 = concatenate([conv1, up4], axis=-1)
    merge4 = SpatialDropout2D(hp.Float('dropout_rate', min_value=0.1, max_value=0.5, step=0.1))(merge4)
    conv8 = residual_block(merge4, hp.Int('conv8_filters', min_value=32, max_value=64, step=32))

    outputs = Conv2D(1, (1, 1), activation='sigmoid')(conv8)

    model = Model(inputs=[inputs], outputs=[outputs])
    model.compile(optimizer=Adam(hp.Float('learning_rate', min_value=1e-5, max_value=1e-3, sampling='LOG')),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])

    return model

tuner = kt.Hyperband(
    build_model,
    objective='val_accuracy',
    max_epochs=20,
    factor=3,
    directory='hyperband',
    project_name='best_cnn_model'
)

# Define the search space
tuner.search_space_summary()

# Train the model with the hyperparameter tuning
tuner.search(images, masks, epochs=50, validation_split=0.2, batch_size=4)

# Retrieve the best model
best_model = tuner.get_best_models(num_models=1)[0]
best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]

print(f"Best Hyperparameters: {best_hyperparameters.values}")

import tensorflow as tf
from tensorflow.keras.layers import Add, MaxPooling2D, SpatialDropout2D, UpSampling2D, Conv2D, BatchNormalization, Activation, Input, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

def residual_block(x, filters, kernel_size=(3, 3), padding='same', strides=1):
    res = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)
    res = BatchNormalization()(res)
    res = Activation('relu')(res)
    res = Conv2D(filters, kernel_size, padding=padding, strides=strides)(res)
    res = BatchNormalization()(res)

    shortcut = Conv2D(filters, kernel_size=(1, 1), padding='same', strides=strides)(x)
    shortcut = BatchNormalization()(shortcut)

    res = Add()([res, shortcut])
    res = Activation('relu')(res)
    return res

def build_model():
    input_shape = (256, 256, 9)
    inputs = Input(shape=input_shape)

    # Encoder
    conv1 = residual_block(inputs, filters=32)
    pool1 = MaxPooling2D((2, 2))(conv1)
    pool1 = SpatialDropout2D(0.1)(pool1)

    conv2 = residual_block(pool1, filters=128)
    pool2 = MaxPooling2D((2, 2))(conv2)
    pool2 = SpatialDropout2D(0.1)(pool2)

    conv3 = residual_block(pool2, filters=128)
    pool3 = MaxPooling2D((2, 2))(conv3)
    pool3 = SpatialDropout2D(0.1)(pool3)

    conv4 = residual_block(pool3, filters=512)
    pool4 = MaxPooling2D((2, 2))(conv4)
    pool4 = SpatialDropout2D(0.1)(pool4)

    # Bottleneck
    bottleneck = residual_block(pool4, filters=1024)

    # Decoder
    up1 = UpSampling2D((2, 2))(bottleneck)
    up1 = Conv2D(512, (2, 2), padding='same')(up1)
    up1 = BatchNormalization()(up1)
    up1 = Activation('relu')(up1)
    merge1 = concatenate([conv4, up1], axis=-1)
    merge1 = SpatialDropout2D(0.1)(merge1)
    conv5 = residual_block(merge1, filters=512)

    up2 = UpSampling2D((2, 2))(conv5)
    up2 = Conv2D(192, (2, 2), padding='same')(up2)
    up2 = BatchNormalization()(up2)
    up2 = Activation('relu')(up2)
    merge2 = concatenate([conv3, up2], axis=-1)
    merge2 = SpatialDropout2D(0.1)(merge2)
    conv6 = residual_block(merge2, filters=128)

    up3 = UpSampling2D((2, 2))(conv6)
    up3 = Conv2D(96, (2, 2), padding='same')(up3)
    up3 = BatchNormalization()(up3)
    up3 = Activation('relu')(up3)
    merge3 = concatenate([conv2, up3], axis=-1)
    merge3 = SpatialDropout2D(0.1)(merge3)
    conv7 = residual_block(merge3, filters=96)

    up4 = UpSampling2D((2, 2))(conv7)
    up4 = Conv2D(64, (2, 2), padding='same')(up4)
    up4 = BatchNormalization()(up4)
    up4 = Activation('relu')(up4)
    merge4 = concatenate([conv1, up4], axis=-1)
    merge4 = SpatialDropout2D(0.1)(merge4)
    conv8 = residual_block(merge4, filters=32)

    outputs = Conv2D(1, (1, 1), activation='sigmoid')(conv8)

    model = Model(inputs=inputs, outputs=outputs)
    model.compile(optimizer=Adam(learning_rate=0.00016993429801653187),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])

    return model

# Build the model
model = build_model()

# Print model summary
model.summary()

history = model.fit(images_train, masks_train,
                    validation_data=(images_val, masks_val),
                    batch_size=8,
                    epochs=50,
                    verbose=1)

# Evaluate the model
loss, accuracy = model.evaluate(images_val, masks_val, verbose=0)
print(f'Validation loss: {loss:.4f}, Validation accuracy: {accuracy:.4f}')

import numpy as np

# Assuming that your model has been trained and you have the `history` object

# Get the predictions on the validation set
predictions = model.predict(images_val)

# Assuming predictions are in the shape (num_samples, height, width, num_classes)
# For binary segmentation, you can convert the predictions to binary masks
binary_predictions = (predictions > 0.5).astype(np.uint8)
binary_predictions = np.squeeze(binary_predictions, axis=-1)  # Remove the extra dimension

# Assuming masks_val is the ground truth masks
# Convert masks_val to binary masks if not already binary
binary_masks_val = (masks_val > 0.5).astype(np.uint8)

# Calculate IoU (Intersection over Union)
intersection = np.logical_and(binary_masks_val, binary_predictions)
union = np.logical_or(binary_masks_val, binary_predictions)
iou = np.sum(intersection) / np.sum(union)

# Calculate Dice coefficient
dice_coefficient = 2 * np.sum(intersection) / (np.sum(binary_masks_val) + np.sum(binary_predictions))

print(f'IoU: {iou:.4f}, Dice Coefficient: {dice_coefficient:.4f}')

overall_accuracy = np.mean(binary_predictions == binary_masks_val)

print(f'Overall Accuracy: {overall_accuracy:.4f}')

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Calculate confusion matrix
cm = confusion_matrix(binary_masks_val, binary_predictions)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

from sklearn.metrics import precision_recall_curve
from sklearn.metrics import average_precision_score

# Calculate precision-recall curve
precision, recall, _ = precision_recall_curve(binary_masks_val, binary_predictions)
average_precision = average_precision_score(binary_masks_val, binary_predictions)

# Plot precision-recall curve
plt.figure()
plt.step(recall, precision, color='b', alpha=0.2, where='post')
plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.ylim([0.0, 1.05])
plt.xlim([0.0, 1.0])
plt.title('Precision-Recall Curve: AP={0:0.2f}'.format(average_precision))
plt.show()

from sklearn.metrics import precision_score, recall_score, f1_score

# Flatten the ground truth masks and predictions
binary_masks_val = (masks_val > 0.5).astype(np.uint8).flatten()
binary_predictions = (predictions > 0.5).astype(np.uint8).flatten()

# Calculate precision, recall, and f1-score
precision = precision_score(binary_masks_val, binary_predictions)
recall = recall_score(binary_masks_val, binary_predictions)
f1 = f1_score(binary_masks_val, binary_predictions)

print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}')

import matplotlib.plt as plt

# Assuming history object is defined as in your code
loss = history.history['loss']
epochs = range(1, len(loss) + 1)

plt.plot(epochs, loss, 'b', label='Training loss')
plt.title('Training Loss - UNET Karachi')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
sns.set()

train_losses, val_losses = history.history['loss'], history.history['val_loss']
plt.plot(train_losses, label = 'train loss')
plt.plot(val_losses, label = 'val loss ')
plt.legend()

import matplotlib.pyplot as plt
import numpy as np

predicted = model.predict(images_val)

# Adjust the figure size to prevent memory issues
fig, axes = plt.subplots(len(images_val), 5, figsize=(15, 3 * len(images_val) // 2))

for i, (img, label, pred, ax) in enumerate(zip(images_val, masks_val, predicted, axes)):
    # Apply binary thresholding
    predicted_binary = (pred > 0.5).astype(np.uint8)

    # Separate the input components
    original_image = img[:, :, :3]  # First 3 channels for the original image (assuming they are RGB)

    minimask = img[:, :, 3:6]       # Next 3 channels for the SAM output (assuming it is in RGB format)
    sam_output = img[:, :, 6:9]     # Last channel for the minimask (assuming it is single-channel)

    row_number = i + 1

    ax[0].imshow(original_image)
    ax[0].set_title(f'{row_number}. Image')
    ax[0].axis('off')

    ax[1].imshow(sam_output, cmap='gray')
    ax[1].set_title('Original SAM')
    ax[1].axis('off')

    ax[2].imshow(minimask, cmap='gray')
    ax[2].set_title('Minimask')
    ax[2].axis('off')

    ax[3].imshow(label, cmap='gray')
    ax[3].set_title('Ground Truth')
    ax[3].axis('off')

    ax[4].imshow(predicted_binary.squeeze(), cmap='gray')  # Ensure the predicted image is binary
    ax[4].set_title('Predicted')
    ax[4].axis('off')

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Function to save images
def save_images(row_number, img, sam_output, minimask, label, predicted_binary):
    # Save images with specified names
    plt.imsave(f'image{row_number}a.jpg', img)
    plt.imsave(f'image{row_number}b.jpg', label, cmap='gray')
    plt.imsave(f'image{row_number}c.jpg', sam_output)
    plt.imsave(f'image{row_number}d.jpg', minimask, cmap='gray')
    plt.imsave(f'image{row_number}e.jpg', predicted_binary.squeeze(), cmap='gray')

# Predict (replace with actual prediction code)
predicted = np.random.rand(len(images_val), 256, 256)
row_number = 212
# Adjust the figure size to prevent memory issues
fig, axes = plt.subplots(len(images_val), 6, figsize=(15, 3 * len(images_val) // 2))

for i, (img, label, pred, ax) in enumerate(zip(images_val, masks_val, predicted, axes)):
    # Apply binary thresholding (replace with actual thresholding if needed)
    predicted_binary = (pred > 0.5).astype(np.uint8)

    # Separate the input components
    original_image = img[:, :, :3]  # First 3 channels for the original image (assuming they are RGB)

    minimask = img[:, :, 3:6]     # Next 3 channels for the SAM output (assuming it is in RGB format)
    sam_output = img[:, :, 6:9]         # Last channel for the minimask (assuming it is single-channel)

    # Add a subplot for the row number
    ax[0].text(0.5, 0.5, f'{i+1}', horizontalalignment='center', verticalalignment='center', fontsize=12, transform=ax[0].transAxes)
    ax[0].axis('off')

    ax[1].imshow(original_image)
    ax[1].set_title('Image')
    ax[1].axis('off')

    ax[2].imshow(sam_output)
    ax[2].set_title('Original SAM', cmap='gray')
    ax[2].axis('off')

    ax[3].imshow(minimask, cmap='gray')
    ax[3].set_title('Minimask')
    ax[3].axis('off')

    ax[4].imshow(label, cmap='gray')
    ax[4].set_title('Ground Truth')
    ax[4].axis('off')

    ax[5].imshow(predicted_binary.squeeze(), cmap='gray')  # Ensure the predicted cnn image is binary
    ax[5].set_title('Predicted')
    ax[5].axis('off')

    # Save images for the specified row (example: row_number = 1 for the first row)
    if i == row_number - 1:
        save_images(row_number, original_image, sam_output, minimask, label, predicted_binary)

plt.tight_layout()
plt.show()